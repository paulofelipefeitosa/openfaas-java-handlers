---
title: "Socc 19 eval"
output:
  pdf_document:
    keep_tex: true
---

```{r rawpb_cmp, fig.width=7, fig.height=5}
# Metrics:
# RuntimeReadyTime -> time between the start of the function and until it is ready to start serving requests.
# ExecID -> Treatment replica ID
# ReqID -> ID of the request within the treatment replica (0 meaning the first request)

require(dplyr)
require(ggplot2)
require(ggpubr)
library(boot)

# Reading data
read_startup <- function(f) {
  df <- read.csv(f) 
  df <- df %>% filter(Metric == "RuntimeReadyTime" & ReqID == 0) %>% select(App, Value_NS)
  colnames(df) <- c("app", "value")
  df$value <- df$value / 10^6 
  df <- df %>% mutate(app = ifelse(app == "NoOp", "NOOP", "Thumbnail Maker"))
  return(df)
}

pb <- read_startup("criu_nobpftrace_nogc_nowarmup.csv")
pb$type <- "Prebaking"
vanilla <- read_startup("nocriu_nobpftrace_nogc_nowarmup.csv")
vanilla$type <- "Vanilla"

pb_noop <- pb %>% filter(app == "NOOP")
vanilla_noop <- vanilla %>% filter(app == "NOOP")
pb_thumb <- pb %>% filter(app == "Thumbnail Maker")
vanilla_thumb <- vanilla %>% filter(app == "Thumbnail Maker")

shapiro.test(pb_noop$value)
shapiro.test(vanilla_noop$value)
wilcox.test(vanilla_noop$value, pb_noop$value, conf.int = T)
shapiro.test(pb_thumb$value)
shapiro.test(vanilla_thumb$value)
wilcox.test(vanilla_thumb$value, pb_thumb$value, conf.int = T)

# Some samples did not pass the Shapiro test, so let's calculate
# the confidence interval using bootstrap and test using a non-parametric
# test.

# Calculate confidence intervals around the mean.
# Inspiration: https://rpubs.com/dgolicher/median_boot
median_cl_boot <- function(x, conf = 0.95) {
    lconf <- (1 - conf)/2
    uconf <- 1 - lconf
    require(boot)
    bmedian <- function(x, ind) median(x[ind])
    bt <- boot(x, bmedian, 1000)
    bb <- boot.ci(bt, type = "perc")
    data.frame(y = median(x), ymin = quantile(bt$t, lconf), ymax = quantile(bt$t, 
        uconf))
}

median_ci_text <- function(x, conf = 0.95) {
    lconf <- (1 - conf)/2
    uconf <- 1 - lconf
    require(boot)
    bmedian <- function(x, ind) median(x[ind])
    bt <- boot(x, bmedian, 1000)
    bb <- boot.ci(bt, type = "perc")
    data.frame(y = max(x) + 12,
               label = paste('Median=[', signif(quantile(bt$t, lconf), 2), ', ', signif(quantile(bt$t, uconf), 2),']', sep=""))
}

# Graphing
p <- c("yellowgreen", "violetred4")  # from viridis color pallete.
cOff <- p[1]
cOn <- p[2]
ggplot(rbind(pb, vanilla), aes(type, value, color=type)) +
  geom_jitter(alpha=0.1) +
  stat_summary(fun.data = median_cl_boot, geom = "errorbar") +
  stat_summary(fun.data = median_ci_text, geom = "text", size=3.5)  +
  facet_wrap(~app) +
  #theme_pubclean() +
  scale_color_manual(values=p) +
  scale_y_continuous(limits = c(0, max(vanilla$value)+20), breaks = seq(0, max(vanilla$value), by = 50)) +
  labs(x="Technique", y="Startup time (ms)")+
  theme(
    legend.position="none",
    axis.title.x=element_blank(),
    panel.grid.major.y = element_line(colour = "darkgray", linetype = 3))

ggsave("startup_cmp_nowarmup.png")
```

```{r multiple_startup_cmp, fig.width=7, fig.height=5}
# Metrics:
# RuntimeReadyTime -> time between the start of the function and until it is ready to start serving requests.
# ExecID -> Treatment replica ID
# ReqID -> ID of the request within the treatment replica (0 meaning the first request)

require(dplyr)
require(ggplot2)
require(ggpubr)
library(boot)

# Reading data
read_startup <- function(f) {
  df <- read.csv(f) 
  df <- df %>% filter(Metric == "RuntimeReadyTime" & ReqID == 0) %>% rename("Value" = "Value_NS")
  df$Value <- df$Value / 10^6 
  df <- df %>%
    group_by(Technique, Runtime, App) %>%
    sample_n(size = 200)
  return(df)
}

pure_startup <- read_startup("startup_nobpftrace.csv")

# Graphing
p <- c("yellowgreen", "violetred4")  # from viridis color pallete.
cOff <- p[1]
cOn <- p[2]
ggplot(pure_startup, aes(factor(Technique, c("Vanilla", "Prebaking", "Prebaking Warm")), Value, colour=App)) +
  geom_jitter(alpha=0.3) +
  #stat_summary(fun.data = median_cl_boot, geom = "errorbar") +
  #stat_summary(fun.data = median_ci_text, geom = "text", size=3.5)  +
  facet_wrap(~Runtime) +
  #theme_pubclean() +
  scale_color_manual(values=p) +
  scale_y_continuous(limits = c(0, max(pure_startup$Value)+20), breaks = seq(0, max(pure_startup$Value), by = 200)) +
  labs(x="Technique", y="Startup time (ms)")+
  theme(
    #legend.position="none",
    axis.title.x=element_blank(),
    axis.text.x = element_text(angle = 45, hjust = 1),
    panel.grid.major.y = element_line(colour = "darkgray", linetype = 3))

ggsave("startup_cmp.png")
```

```{r multiple_latency_cmp, fig.width=7, fig.height=5}
# Metrics:
# RuntimeReadyTime -> time between the start of the function and until it is ready to start serving requests.
# ExecID -> Treatment replica ID
# ReqID -> ID of the request within the treatment replica (0 meaning the first request)

# Reading data
read_latency <- function(f) {
  df <- read.csv(f) 
  df <- df %>% filter((Metric == "LatencyTime" | Metric == "Latency") & ReqID == 0) %>% rename("Value" = "Value_NS")
  df$Value <- df$Value / 10^6 
  df <- df %>%
    group_by(Technique, Runtime, App) %>%
    sample_n(size = 200)
  return(df)
}

pure_latency <- read_latency("startup_nobpftrace.csv")

# Graphing
p <- c("yellowgreen", "violetred4")  # from viridis color pallete.
cOff <- p[1]
cOn <- p[2]
ggplot(pure_latency, aes(factor(Technique, c("Vanilla", "Prebaking", "Prebaking Warm")), Value, colour=App)) +
  geom_jitter(alpha=0.3) +
  #stat_summary(fun.data = median_cl_boot, geom = "errorbar") +
  #stat_summary(fun.data = median_ci_text, geom = "text", size=3.5)  +
  facet_wrap(~Runtime) +
  #theme_pubclean() +
  scale_color_manual(values=p) +
  #scale_y_continuous(limits = c(0, max(pure_latency$Value)+20), breaks = seq(0, max(pure_latency$Value), by = 200)) +
  scale_y_continuous(limits = c(0, 600), breaks = seq(0, 600, by = 100)) +
  labs(x="Technique", y="Latency (ms)")+
  theme(
    #legend.position="none",
    axis.title.x=element_blank(),
    axis.text.x = element_text(angle = 45, hjust = 1),
    panel.grid.major.y = element_line(colour = "darkgray", linetype = 3))

ggsave("latency_cmp_600scale.png")
```

```{r multiple_servicetime_cmp, fig.width=7, fig.height=5}
# Metrics:
# RuntimeReadyTime -> time between the start of the function and until it is ready to start serving requests.
# ExecID -> Treatment replica ID
# ReqID -> ID of the request within the treatment replica (0 meaning the first request)

# Reading data
read_servicetime <- function(f) {
  df <- read.csv(f) 
  df <- df %>% filter((Metric == "ServiceTime") & ReqID < 200) %>% rename("Value" = "Value_NS")
  df$Value <- df$Value / 10^6 
  #df <- df %>% mutate(app = ifelse(app == "NOOP", "NoOp", "Thumbnail Maker"))
  return(df)
}

pure_servicetime <- read_servicetime("startup_nobpftrace.csv")

# Graphing
p <- c("yellowgreen", "violetred4")  # from viridis color pallete.
cOff <- p[1]
cOn <- p[2]
ggplot(pure_servicetime %>% 
         filter(App == "NoOp" & ReqID == 0), 
       aes(Value, colour=factor(Technique, c("Vanilla", "Prebaking", "Prebaking Warm")))) +
  #geom_jitter(alpha=0.3) +
  #geom_point(size = 0.5) +
  stat_ecdf(geom = "step") +
  #stat_summary(fun.data = median_cl_boot, geom = "errorbar") +
  #stat_summary(fun.data = median_ci_text, geom = "text", size=3.5)  +
  facet_wrap(. ~ Runtime) +
  #theme_pubclean() +
  #scale_color_manual(values=p) +
  #scale_y_continuous(limits = c(0, 200)) +
  labs(x="Service Time of First Request (ms)", y="F(Service Time)", colour = "Technique") +
  theme(
    #legend.position="none",
    #axis.title.x=element_blank(),
    #axis.text.x = element_text(angle = 45, hjust = 1),
    panel.grid.major.y = element_line(colour = "darkgray", linetype = 3))

ggsave("noop_servicetime_ecdf_cmp.png")

ggplot(pure_servicetime %>% 
         filter(App == "Thumbnailator" & ReqID == 0),
       aes(Value, colour=factor(Technique, c("Vanilla", "Prebaking", "Prebaking Warm")))) +
  #geom_jitter(alpha=0.3) +
  #geom_point(size = 0.5) +
  stat_ecdf(geom = "step") +
  #stat_summary(fun.data = median_cl_boot, geom = "errorbar") +
  #stat_summary(fun.data = median_ci_text, geom = "text", size=3.5)  +
  facet_wrap(. ~ Runtime) +
  #theme_pubclean() +
  #scale_color_manual(values=p) +
  #scale_y_continuous(limits = c(0, 200)) +
  labs(x="Service Time of First Request (ms)", y="F(Service Time)", colour = "Technique") +
  theme(
    #legend.position="none",
    #axis.title.x=element_blank(),
    #axis.text.x = element_text(angle = 45, hjust = 1),
    panel.grid.major.y = element_line(colour = "darkgray", linetype = 3))

ggsave("thumb_servicetime_ecdf_cmp.png")
```


```{r bpfstrace_cmp, fig.width=7, fig.height=5}
# Metrics:
# InitializationTime -> time between the exec of the function and until it is ready to start serving requests.
# ExecID -> Treatment replica ID
# ReqID -> ID of the request within the treatment replica (0 meaning the first request)

require(ggplot2)

bpftrace_startup <- read.csv("treated_startup_bpftrace.csv") %>% filter(is.na(Value) == FALSE)

calc_perc <- function(df){
  df <- df %>%
    group_by(Runtime, App, Technique, Metric) %>%
    summarise(sum=sum(Value),
              med=median(Value),
              p99=quantile(Value, c(0.99))) %>%
    mutate(perc=signif((sum/sum(sum))*100, digits=3))
  return(df)
}

perc_bpftrace_startup <- calc_perc(bpftrace_startup)

p <- c("yellowgreen", "skyblue4", "violetred4")  # from viridis color pallete.
ggplot(perc_bpftrace_startup, aes(fill=Technique, y=perc, x=Metric)) +
  facet_wrap(Runtime~App) +
  geom_col(position=position_dodge2(), color = "black", size=0.2, alpha=0.9) +
  geom_text(aes(label=paste(perc, "%", sep=""), y=perc+2), position = position_dodge(width=1), size=3, hjust = 0)+
  labs(x="Startup Component", y="Percentage of the Startup Time (%)", fill="Technique:")+
  scale_fill_manual(values=p) +
  scale_x_discrete(limits=c("ST", "APPINIT","RTS", "EXEC", "CLONE")) +
  #scale_y_continuous(limits=c(0,110), breaks = seq(0, 110, 20)) +
  coord_flip() +
  #theme_pubclean() +
  theme_bw() +
  theme(
    panel.grid.major.y = element_line(colour = "darkgray", linetype = 3))

ggsave("new_startup_components.png")

ggplot(perc_bpftrace_startup %>% filter(Metric != c("EXEC", "CLONE"))) +
  facet_grid(Runtime~App) +
  geom_bar(aes(y = med, 
               x = factor(Technique, c("Vanilla", "Prebaking", "Prebaking Warm")), 
               fill = factor(Metric, c("ST", "APPINIT", "RTS"))), 
           stat = "identity") +
  labs(fill = "Metric", x = "Technique", y = "Cold Start Latency (ms)") +
  #theme_pubclean() +
  theme_bw() +
  scale_fill_grey(start = 0, end = 0.85) +
  theme(panel.grid.major.y = element_line(colour = "darkgray", linetype = 3),
        axis.text.x = element_text(angle = 45, hjust = 1))

ggsave("new_stacked_startup_components_bar_plot.png")

calc_absolute <- function(df, appName, m){
  aux <- df %>%
    filter(app==appName & metric==m) %>%
    group_by(metric) %>%
    summarise(value=mean(value))
  aux$value
}

sprintf("Impact of the function complexity in prebaking: %f", calc_absolute(pb, "Thumbnail Maker", "APPINIT")/calc_absolute(pb, "NOOP", "APPINIT"))

sprintf("Impact of the function complexity in vanilla: %f", calc_absolute(vanilla, "Thumbnail Maker", "APPINIT")/calc_absolute(vanilla, "NOOP", "APPINIT"))

calc_absolute(vanilla, "Thumbnail Maker", "APPINIT")
calc_absolute(vanilla, "NOOP", "APPINIT")
calc_absolute(pb, "Thumbnail Maker", "APPINIT")
calc_absolute(pb, "NOOP", "APPINIT")

```

``` {r rts-confidence-interval}
require(reshape2)
require(Rmisc)

ggplot(summarySEwithin(vanilla[which(vanilla$metric == "RTS"), ], 
                       measurevar="value", 
                       withinvars="app",
                       #idvar="subject", 
                       na.rm=FALSE, 
                       conf.interval=.95),
       aes(x = app, y = value, group = 1)) +
  geom_line() +
  geom_errorbar(width=.1, aes(ymin=value-ci, ymax=value+ci)) +
  geom_point(shape=21, size=3, fill="white") +
  labs(y = "Runtime Startup Time (ms)", x = "Vanilla Application") +
  theme_bw()

ggsave("confidence-interval-rts-vanilla.png")
```

```{r service_time_cmp, fig.width=7, fig.height=5}
# Metrics:
# RuntimeReadyTime -> time between the start of the function and until it is ready to start serving requests.
# ExecID -> Treatment replica ID
# ReqID -> ID of the request within the treatment replica (0 meaning the first request)

require(dplyr)
require(ggplot2)
require(ggpubr)

# Reading data
read_service_time <- function(f) {
  df <- read.csv(f) 
  df <- df %>% filter(Metric == "ServiceTime") %>% select(App, Value_NS)
  colnames(df) <- c("app", "value")
  df$value <- df$value / 10^6 
  df <- df %>% mutate(app = ifelse(app == "NoOp", "NOOP", "Thumbnail Maker"))
  return(df)
}

pb <- read_service_time("criu_nobpftrace_nogc_nowarmup.csv")
pb$type <- "Prebaking"
vanilla <- read_service_time("nocriu_nobpftrace_nogc_nowarmup.csv")
vanilla$type <- "Vanilla"

pb_noop <- pb %>% filter(app == "NOOP")
vanilla_noop <- vanilla %>% filter(app == "NOOP")
pb_thumb <- pb %>% filter(app == "Thumbnail Maker")
vanilla_thumb <- vanilla %>% filter(app == "Thumbnail Maker")

p <- c("yellowgreen", "violetred4")
cOff <- p[1]
cOn <- p[2]
ggplot(rbind(pb, vanilla), aes(value, linetype=type, color=type)) +
  facet_wrap(~app, scales="free") +
  stat_ecdf(size=1.5) +
  #theme_pubclean() +
  theme_bw() +
  scale_color_manual(values=p) +
  labs(y = "ECDF", x="Tempo de Serviço (ms)", linetype="Técnica", color="Técnica") +
  theme(
    legend.position="bottom",
    panel.grid.major.x = element_line(colour = "darkgray", linetype = 3))
ggsave("service_time.png")

```

```{r, fig.asp=0.5}
# Ambos os csv's (Criu e NoCriu) possuem as seguintes métricas:
# MainEntry -- Timestamp em nanosegundos do momento em que a app entrou no código Main.
# MainExit -- Timestamp em nanosegundos do momento em que a app saiu do código Main.
# Read2Serve -- Timestamp em nanosegundos do momento em que a função da app começou a atender a requisição.
# RuntimeReadyTime -- Tempo em nanosegundos que levou para a função da app começar a atender a requisição.
# ServiceTime -- Tempo em nanosegundos que levou para a função da app começar a servir/computar a requisição.
# LatencyTime -- Tempo em nanosegundos que levou para a app responder a requisição.

# Porém, a execução sem criu (NoCriu) possui as seguintes métricas adicionais:

# LoadedClasses -- Quantidade de classes carregadas na função da app no momento da requisição
# FindingClassesTime -- Tempo em nanosegundos que a função da app passou apenas encontrando as classes, ou seja, o tempo de lê os dados do arquivo .class e criar o objeto Class<?>.
# CompilingClassesTime -- Tempo em nanosegundos que a função da app passou apenas criando as instâncias das classes pelo construtor de default (é sempre garantido que ele existe!).
# LoadClassesTotalTime -- Tempo em nanosegundos que a função da app passou lendo as entradas do jar da função sintética (o nome dos arquivos .class da função sintética gerada), carregando e compilando todas as classes.
# LoadingClassesOverheadTime -- Tempo em nanosegundos que durante o carregamento das classes a função da app não estava encontrando ou compilando classes, podemos interpretar como (LoadClassesTotalTime - FindingClassesTime - CompilingClassesTime).

require(dplyr)
require(ggplot2)
require(reshape)
require(ggpubr)

read_service_time <- function(f) {
  df <- read.csv(f) 
  df <- data.frame(
    Complexity=df[df$Metric=="ServiceTime", ]$Loaded_Classes,
    Value=df[df$Metric=="ServiceTime", ]$KernelTime_NS+df[df$Metric=="RuntimeReadyTime", ]$KernelTime_NS)
  colnames(df) <- c("app", "value")
  df$value <- df$value / 10^6 
  df <- df %>% mutate(app = ifelse(app == "50", "Small", ifelse(app == 250, "Medium", "Big")))
  return(df)
}
pb <- read_service_time("criu-nobpf-nogc-warmup-noop-class-loader.csv")
pb$type <- "Prebaking-Warmup"
pb1 <- read_service_time("criu-nobpf-nogc-nowarmup-noop-class-loader.csv")
pb1$type <- "Prebaking-NOWarmup"
vanilla <- read_service_time("nocriu-nobpftrace-nogc-nowarmup-noop-class-loader.csv")
vanilla$type <- "Vanilla"

calculate_median <- function(df, app) {
  df.t <- wilcox.test(df[df$app == app, ]$value, conf.int = T)
  return(data.frame(
    app=app,
    value=df.t$estimate,
    min=df.t$conf.int[1],
    max=df.t$conf.int[2]))
}

calculate_median(pb, "Small")
calculate_median(pb, "Medium")
calculate_median(pb, "Big")
calculate_median(pb1, "Small")
calculate_median(pb1, "Medium")
calculate_median(pb1, "Big")
calculate_median(vanilla, "Small")
calculate_median(vanilla, "Medium")
calculate_median(vanilla, "Big")

calculate_ratio <- function(pb, vanilla, app) {
  pb.t <- wilcox.test(pb[pb$app == app, ]$value, conf.int = T)
  vanilla.t <- wilcox.test(vanilla[vanilla$app == app, ]$value, conf.int = T)
  return(data.frame(
    type=pb$type,
    app=app,
    value=(vanilla.t$estimate/pb.t$estimate)*100,
    min=(vanilla.t$conf.int[1]/pb.t$conf.int[1])*100,
    max=(vanilla.t$conf.int[2]/pb.t$conf.int[2])*100))
}

result <- calculate_ratio(pb, vanilla, "Small")
result <- rbind(result, calculate_ratio(pb, vanilla, "Medium"))
result <- rbind(result, calculate_ratio(pb, vanilla, "Big"))
result <- rbind(result, calculate_ratio(pb1, vanilla, "Small"))
result <- rbind(result, calculate_ratio(pb1, vanilla, "Medium"))
result <- rbind(result, calculate_ratio(pb1, vanilla, "Big"))


ggplot(result, aes(x=app, value, fill=type)) +
  #geom_errorbar(aes(ymin=min, ymax=max), width=.5) +
  geom_bar(position="dodge", stat = "identity") +
  theme_pubclean() +
  labs(y = "Startup Time Improvement (%)", x="Function Size", fill = "Type") +
  scale_x_discrete(limits=c("Small", "Medium", "Big")) +
  theme(
    legend.position="bottom",
    panel.grid.major.x = element_line(colour = "darkgray", linetype = 3))

ggsave("impact_function_size_cmp.png")
```


```{r, fig.asp=0.5}
require(dplyr)
require(ggplot2)
require(reshape)
require(ggpubr)

read_ncl_stats <- function(f) {
  df <- read.csv(f) %>% rename("Complexity" = "Loaded_Classes") %>% filter(is.na(Value) == FALSE)
  df$Value <- df$Value / 10^6 
  df <- df %>% mutate(Complexity = ifelse(Complexity == "50", "Small", ifelse(Complexity == "250", "Medium", "Big")))
  return(df)
}
vanilla_ncl <- read_ncl_stats("treated_nocriu_ncl_startup_bpftrace.csv")

calc_perc <- function(df){
  df <- df %>%
    group_by(Runtime, App, Technique, Complexity, Metric) %>%
    summarise(sum=sum(Value),
              med=median(Value),
              p99=quantile(Value, c(0.99))) %>%
    mutate(perc=signif((sum/sum(sum))*100, digits=3))
  return(df)
}

vanilla_ncl_perc_bpftrace_stats <- calc_perc(vanilla_ncl)

p <- c("yellowgreen", "skyblue4", "violetred4")  # from viridis color pallete.
ggplot(vanilla_ncl_perc_bpftrace_stats %>% filter(Metric != c("EXEC", "CLONE"))) +
  geom_bar(aes(y = med, 
               x = factor(Complexity, c("Small", "Medium", "Big")), 
               fill = factor(Metric, c("ST", "APPINIT", "RTS"))), 
           stat = "identity") +
  labs(fill = "Metric", x = "Function Size", y = "Cold Start Latency (ms)") +
  #theme_pubclean() +
  theme_bw() +
  scale_fill_grey(start = 0, end = 0.85) +
  theme(panel.grid.major.y = element_line(colour = "darkgray", linetype = 3),
        axis.text.x = element_text(angle = 45, hjust = 1))

ggsave("stacked_ncl_latency_components_bar_plot.png")

calculate_median <- function(df, app) {
  df.t <- wilcox.test(df[df$app == app, ]$value, conf.int = T)
  return(data.frame(
    type=df$type,
    app=app,
    value=df.t$estimate,
    min=df.t$conf.int[1],
    max=df.t$conf.int[2]))
}

result <- calculate_median(vanilla, "Small")
result <- rbind(result, calculate_median(vanilla, "Medium"))
result <- rbind(result, calculate_median(vanilla, "Big"))

ggplot(result, aes(x=app, y=value)) +
  geom_bar(position="dodge", stat="identity", fill="violetred4") +
  geom_errorbar(aes(ymin=min, ymax=max), width=.5) +
  theme_pubclean() +
  labs(y = "Startup Time (ms)", x="Function Size") +
  scale_x_discrete(limits=c("Small", "Medium", "Big")) +
  theme(
    legend.position="bottom",
    panel.grid.major.x = element_line(colour = "darkgray", linetype = 3))

ggsave("impact_function_size_vanilla.png")
```

# CRIU Restore 

ResolveSharedResources seria Resolve Shared Resources + Fork the process tree (checando dumps, mount procfs (~63% do tempo), faz fork da task root)
ForkingTime seria só leitura das páginas de memória de todos os processos na árvore (faz fork das tasks childrens)
Restore basic resources seria: tempo restaurando memory mappings exact location + file descriptors + timers + credentials + threads (Restore the rest)


```{r criu_restore_desiccation, fig.asp=0.5}
require(dplyr)
require(ggplot2)
require(ggpubr)

read_ncl_criu_restore_stats <- function(f) {
  df <- read.csv(f) %>% rename("Complexity" = "Loaded_Classes", "Value" = "Value_NS") %>% filter(ReqID == 0 & Metric %in% c("RuntimeReadyTime", "ResolveSharedResourcesTime", "ForkingTime", "RestoreResourcesTime", "SwitchRestoreContinueTime"))
  rrt_rows <- which(df$Metric == "RuntimeReadyTime")
  criu_stats_rows <- which(df$Metric != "RuntimeReadyTime")
  df[rrt_rows, ]$Value <- df[rrt_rows, ]$Value / (10^6)
  df[criu_stats_rows, ]$Value <- df[criu_stats_rows, ]$Value * (10^3)
  df <- df %>% mutate(Complexity = ifelse(Complexity == "50", "Small", "Big"))
  return(df)
}
criu_restore_stats <- read_ncl_criu_restore_stats("ncl_criu_restore.csv")

calc_perc <- function(df){
  df <- df %>%
    filter(Metric != "RuntimeReadyTime") %>%
    group_by(Runtime, App, Technique, Complexity, Metric) %>%
    summarise(sum=sum(Value),
              med=median(Value),
              p99=quantile(Value, c(0.99))) %>%
    mutate(perc=signif((sum/sum(sum))*100, digits=3))
  return(df)
}

perc_criu_restore_stats <- calc_perc(criu_restore_stats)

p <- c("yellowgreen", "skyblue4", "violetred4")  # from viridis color pallete.
ggplot(perc_criu_restore_stats) +
  geom_bar(aes(y = med, 
               x = factor(Complexity, c("Small", "Big")), 
               fill = factor(Metric, c("SwitchRestoreContinueTime", "RestoreResourcesTime", "ForkingTime", "ResolveSharedResourcesTime"))), 
           stat = "identity") +
  labs(fill = "Metric", x = "Function Size", y = "CRIU Restore Latency (ms)") +
  #theme_pubclean() +
  theme_bw() +
  scale_fill_grey(start = 0, end = 0.85) +
  theme(panel.grid.major.y = element_line(colour = "darkgray", linetype = 3),
        axis.text.x = element_text(angle = 45, hjust = 1))

ggsave("stacked_ncl_criu_restore_components_bar_plot.png")
```
